% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{boost_regression}
\alias{boost_regression}
\title{Boosting for Regression using Any R Model}
\usage{
boost_regression(model_creator, X, y, B, model_args, eta = 0.1, verbose = TRUE)
}
\arguments{
\item{model_creator}{An R function that returns a new Model object with
fit() and predict() methods}

\item{X}{Feature matrix (n x p)}

\item{y}{Response vector (length n)}

\item{B}{Number of boosting iterations}

\item{model_args}{Named list of additional arguments to pass to model$fit()}

\item{eta}{Shrinkage parameter (learning rate), default 0.1}

\item{verbose}{Whether to print progress (default: TRUE)}
}
\value{
A list containing:
\itemize{
\item models: List of B fitted model objects
\item f_hat: Final predictions on training data
\item y: Original response vector (needed for variable importance)
\item residuals_history: Matrix of residuals at each iteration (n x B+1)
Column 0 contains initial residuals (y), columns 1:B contain updated residuals
\item predictions_history: Matrix of base learner predictions (n x B)
\item eta: The shrinkage parameter used
\item B: Number of iterations
}
}
\description{
Implements Algorithm 8.2 for gradient boosting with regression trees
or any other base learner compatible with the Model R6 class interface.
This implementation uses the negative gradient of squared error loss.
}
\details{
For squared error loss L(y,f) = 0.5*(y-f)^2, the negative gradient is
-dL/df = y - f, which equals the residuals. Each iteration fits a base
learner to these residuals (pseudo-residuals) and updates predictions.
}
\examples{
\dontrun{
library(rpart)

# Model creator function
model_creator <- function() {
  Model$new(rpart::rpart)
}

# Generate data
set.seed(123)
X <- matrix(rnorm(200), ncol = 4)
y <- 2*X[,1] - 1.5*X[,2] + rnorm(50)

# Run boosting
result <- boost_regression(
  model_creator = model_creator,
  X = X, y = y, 
  B = 100, eta = 0.1,
  model_args = list(maxdepth = 2)
)

# Make predictions
preds <- predict_boost(result, X)
sqrt(mean((y - preds)^2))  # RMSE
}

}
